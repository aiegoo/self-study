# 아파치 Kafka 따라잡기 1편

**✔ 아파치 Kafka 따라잡기 : 확장성과 고가용성을 지닌 메시지 브로커 목차**

|CHAPTER|Description|
|--|--|
|1장|카프카소개|
|2장|카프카설치|
|3장|카프카 클러스터 설정|
|4장|카프카 디자인|
|5장|생산자 작성|
|6장|소비자 작성|
|7장|카프카 연동|
|8장|카프카 도구|

## 1장 카프카 소개

메시지 퍼블리싱은 다양한 애플리케이션의 메시지를 서로 전달 할 수 있도록 연결하는 구조이며, 대표적인 예로 메시지 브로커인 카프카를 들 수 있다.

카프카는 실시간으로 대량의 정보를 다루고 여러 정보 소비자에게 빠르게 전달하는 과정에서 생기는 문제점을 해결한 솔루션이다.

카프카를 통해 정보 소비자는 정보 생성자에 대해 알 필요 없고 생산자는 누가 최종소비자인지 알 필요 없이 서로 연동시켜준다.

**🤔 카프카란?**

아파치 카프카는 오픈소스 분산 발행-구독 메시징 시스템으로 다음과 같은 특징으로 디자인 되었다.

1. 비휘발성 메시징
2. 높은 처리량
3. 분산
4. 다양한 클라이언트 지원
5. 실시간

**카프카의 필요성**

아파치 카프카는 하둡 시스템으로의 병렬 로드와 클러스터의 장비들에 의한 실시간 분할 소비를 지원해서 오프라인과 온라인 처리를 통합하는 것을
목적으로 한다. 카프카는 활동 스트림 데이터를 처리하는 데 유용하다는 점에서 스크라이브 또는 플럼과 유사해 보이지만 아키텍처 관점에서 보면 기존의
액티브엠큐 또는 래빗엠큐와 같은 메시징 시스템에 더 가깝다.

## 2장 카프카 설치

[Download Kafka](https://kafka.apache.org/downloads)

**✔ 카프카 설치 관련 명령어**

```
wget http://~~.tgz
tar svf kafka~.tgz
wget https://~.tgz
tar xvf kafka~.tgz
```

**✔ 사전에 필요한 소프트웨어 설치**

카프카는 스칼라를 사용하고 ./sbtool을 사용해 카프카 바이너리를 묶는다. sbt는 자바 1.6 또는 이후 버전이 있어야 하는 스칼라와 자바 프로젝트 빌드 도구이다.

1. [오라클 웹사이트](https://www.oracle.com/java/technologies/downloads/)에서 jdk-6u45-linux-x64.bin을 내려받는다.

2. 실행 권한을 준다.

- 관련 명령어 

```
chmod +x
```

3. 인스톨러를 실행한다.

4. 마지막으로 JAVA_HOME 환경변수를 추가한다.

- 관련 명령어

```
echo
```

**✔ 카프카 빌딩**

1. 현재 디렉토리를 다음 명령어를 통해 내려받은 카프카 디렉토리로 이동한다.

```
cd kafka-<VERSION>
```

2. 다음 명령을 통해 카프카를 빌드하는데 필요한 스칼라 컴파일러, 스칼라 라이브러리, 주키퍼, 코어 카프카 업데이트, 하둡 소비자/생성자 업데이트 같은 모든 의존성 항목을 내려받는다

```
#./sbt update
```

3. 마지막으로 다음 명령어를 통해 코어 카프카, 자바 예제, 하둡 생산자/소비자 전체 소스 코드를 컴파일하고 JAR 파일로 패키징한다.

```
#./sbt package
```

4. 카프카 0.8에선 다음의 추가 명령을 통해 의존성 아티펙트를 만드는 것이 필요하다.

```
#./sbt assembly-package-dependency
```

## 3장 카프카 클러스터 설정

카프카는 다음과 같은 여러 종류의 클러스터를 생성할 수 있다.

1. 단일 노드 단일 브로커 클러스터
2. 단일 노드 다중 브로커 클러스터
3. 다중 노드 다중 브로커 클러스터

**✔ 단일 노드 단일 브로커 클러스터 예시**

주키퍼 서버 구동
- 카프카는 기본 설정으로 단일 로컬 주키퍼 인스턴스로 구동하는 최소한의 주키퍼 설정 파일을 제공한다.

🤔 [주키퍼](https://zookeeper.apache.org/)란?
- 주키퍼는 카프카 브로커와 소비자 사이를 조율하는 인터페이스 역할을 한다. 
- 주키퍼는 파일시스템과 유사한 형태의 계층화된 네임스페이스 데이타 등록을 통해 분산 프로세스를 조율한다. 
- 주키퍼는 상태 정보, 설정 정보, 위치 정보 등의 조율에 필요한 데이터를 저장하도록 디자인 되었다.

주키퍼 시작 명령어

```
#  bin/zookeeper-server-start.sh config/zookeeper.properties
```

카프카 브로커 시작 명령어

```
# bin/kafka-server-start.sh config/server.properties
```

카프카 토픽 생성 명령어

```
# bin/kafka-create-topic.sh --zookeeper 
localhost:2181 --replica 1 --partition 1 --topic kafkatopic
```

메시지를 보내기 위한 생산자 구동
- 카프카는 사용자에게 커맨드라인 입력을 받고 카프카 클러스터에 메시지를 발행하는 커맨드라인 생산자 클라이언트를 제공한다.
- 기본 설정으로 새로운 입력 라인은 하나의 메시지로 다룬다.

```
# bin/kafka-console-producer.sh --broker`list localhost:9092 --topic kafkatopic
```

메시지를 보내기 위한 소비자 구동
- 카프카는 메시지를 소비하기 위한 커맨드라인 소비자를 제공한다. 다음 명령어는 콘솔 기반의 소비자를 시작하는 명령어다.
콘솔 기반 소비자는 시작하자마자 카프카 브로커에 생성된 토픽을 구독하여 커멘드 라인으로 보여준다.

```
# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafkatopic --from-beginning
```

## 4장 카프카 디자인

- 카프카 디자인의 토대
- 카프카 메시지 압축
- 카프카 클러스터 미러링
- 카프카 리플리케이션

**✔ 카프카 디자인의 핵심 토대**

기본 구조로, 생산자는 카프카 브로커에 생성된 카프카 토픽으로 메시지를 보낸다. 카프카 브로커는 카프카 서버로 동작한다.
소비자는 메시지를 얻기 위해 카프카 토픽을 구독한다.

<img src="/image/kafka_architecture.PNG" alt="no-image">

하나의 메시지는 소비자 그룹 안의 하나의 프로세스에 의해 소비되고
하나의 메시지가 여러 소비자에 의해 소비돼야 하는 요규조건이 있다면 이러한 소비자들은 다른 소비자 그룹에 속하도록 해야 한다.

<img src="/image/kafka_2.PNG" alt="no-image">

카프카 디자인을 보면 소비한 메시지의 상태는 메시지 소비자에 의해서만 유지되고 무엇이 누구에게 소비되었는지에 대한 기록은 카프카 브로커에 유지하지 않는다.

**✔ 카프카 주요 설계 요소**

- 카프카의 주요 토대는 메시지를 파일 시스템에 저장하고 캐싱하는 것이다.
- 카프카는 필요에 따라 메시지 소비 후 다시 메시지를 소비할 수 있게 메시지의 장기 보관을 지원한다.
- 카프카는 네트워크 부하를 줄이기 위해 메시지를 그룹으로 묶는 메시지 집합을 사용한다.
- 메시지 소비에 대한 메타정보가 서버에 저장되는 대부분의 메시지 시스템과 다르게 카프카는 소비자 레벨에서 소비된 메시지의 상태를 가지고 있다. 그러므로 다음과 같은 이슈를 해결할 수 있다.
1) 실패에 따른 메시지 유실
2) 단일 메시지의 복수 전달
- 기본 설정으로 소비자는 상태를 주키퍼에 저장한다. 또한 카프카는 온라인 트랜잭션 처리(OLTP) 애플리케이션으로 사용하는 다른 스토리지 시스템에 저장할 수 있다.
- 카프카에서 생산자 소비자는 통상적인 끌기 밀기(push-and-pull) 모델 방식으로 동작한다. 생산자가 메시지를 카프카 브로커로 밀어 넣으면 소비자는 브로커로부터 메시지를 끌어온다.
- 카프카에서 마스터 개념은 없고 모든 브로커를 피어로 다룬다는 점과 브로커 메타데이터를 주키퍼 보관하고 생산자와 소비자에 공유한다는 점 때문에 카프카 브로커를 언제든지 제거 또는 추가하기 쉽다.
- 카프카 0.7.x에는 주키퍼 기반의 부하 분산을 통해 생산자가 브로커를 동적으로 찾는다. 카프카 0.8.x 버전에서는 카프카 메타데이터 API를 사용하고 주키퍼는 이용 가능한 브로커 리스트를 확인하는 데만 쓰인다.
- 생산자는 메시지를 브로커에 보내는데, 비동기 또는 동기 모드를 선택할 수 있다.

**✔ 카프카 메시지 압축**

카프카는 메시지를 그룹화 하는 데 메시지 집합 기능을 이용한다. 따라서 메시지 그룹 압축 기능을 지원한다.
데이터는 생산자가 GZIP 또는 Snappy 압축 프로토콜을 이용해서 압축하고 메시지 소비자에 의해 압축 해제 된다.

**✔ 카프카 클러스터 미러링**
카프카 미러링 기능은 기존 클러스터의 복사본을 만드는데 사용한다. 예를 들면 활성 데이터 센터로부터 비활성 데이터 센터로 복제하는 경우가 있다. 카프카는 원본 클러스터로부터 대상 클러스터로 미러링을 만드는 도구를 제공한다. 

**✔ 카프카 리플리케이션**

메시지 파티셔닝 : 카프카의 메시지 파티셔닝 전략은 브로커 단에서 사용한다. 어떻게 메시지가 파티션될 것인지는 메시지 생산자에 의해 결정하고 브로커는 메시지가 들어온 순서대로 저장한다. 파티션의 개수는 브로커 내의 각 토픽에 설정할 수 있다.

카프카는 높은 확장성을 가지고 있지만, 카프카 클러스터의 메시지 견고성과 확장성을 위해서 어떠한 브로커 실패 시에도 복제본을 사용해 메시지를 발행하고 소비하는 것을 보장한다. 카프카에서 소비자와 생산자 둘 다 리플리케이션을 고려해 동작한다. 다음 그림은 카프카의 리플리케이션 동작을 나타낸다.

<img src="/image/Kafka_Cluster_Replication.png" alt="no-image">

리플리케이션에서 각 파티션은 'n'개의 리플리카를 가지고 있고 'n-1'실패까지 메시지 전달을 보장한다. 'n'개의 리플리카 중 하나의 리플리카는 나머지 리플리카의 리드 리플리카로 행동한다. 주키퍼는 리드 리플리카와 현재 동기된 팔로워 리플리카 정보를 가지고 있다.

각 리플리카는 메시지 일부를 로컬 로그와 오프셋으로 저장하고 주기적으로 디스크에 싱크(sync)한다. 이 작업은 또한 메시지가 모든 리플리카에 쓰여지거나 전부 쓰이지 않았다는 것을 보장한다.

리드 리플리카가 메시지 파티션을 자신의 로컬 로그로 쓰는 중이거나 메시지 생산자에 확인 응답을 보내기 전에 실패가 발생하면 생산자는 메시지 파티션을 새로운 리더 브로커에 다시 보낸다.

새로운 리플리카 선출은 모든 동기화 리플리카가 자신을 주키퍼에 등록함으로서 이루어진다.

첫 번째 등록된 리플리카가 새로운 리드 리플리카가 되고 다른 모든 등록된리플리카가 팔로워가 된다. 

**✔ 카프카 리플리케이션 모드**

1. 동기 리플리케이션
생산자는 첫 번째로 주키퍼로부터 리드 리플리카를 식별하고 메시지를 발행한다. 메시지를 발행하자마자 리드 리플리카의 로그에 쓴다. 그리고 모든 리드 리플리카의 팔로워들은 메시지를 끌어오기 시작한다. 하나의 채널을 사용하기 때문에 메시지의 순서가 보장된다. 각 팔로워 리플리카들이 로그로 쓰는 것을 완료하면 리드 리플리카에 확인 응답을 보낸다. 모든 리플리카가 완료되고 모든 확인 응답을 받으면 리드 리플리카는 생산자에 확인 응답을 보낸다.

2. 비동기 리플리케이션
앞의 모드와 단 한 가지 차이점은 리드 리플리카가 메시지를 자신의 로컬 로그에 쓰자마자 확인 응답 메시지를 메시지 클라이언트에 보내고 팔로워 리플리카로 부터 메시지 확인 응답을 기다리지 않는다는 것이다. 이 모드의 단점은 브로커 실패 시 메시지 전달이 보장되지 않는다는 점이다.
